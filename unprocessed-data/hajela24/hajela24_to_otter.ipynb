{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90584293-4250-46e4-9ab1-e5d713e561f7",
   "metadata": {},
   "source": [
    "# Reformat the data from Ridley+2023 on AT2017bcc into the OTTER JSON format\n",
    "\n",
    "### Metadata First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ba0e3d-c39c-484f-a153-5ad302ae337b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import otter\n",
    "\n",
    "from astropy import units as u\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    otterdir: str\n",
    "    indir: str\n",
    "    \n",
    "@dataclass\n",
    "class Param:\n",
    "    name: float | str | int\n",
    "    unit: str\n",
    "    description: str = None\n",
    "\n",
    "    \n",
    "args = Args(\n",
    "    otterdir=\".otter\",\n",
    "    indir=os.getcwd()\n",
    ")\n",
    "\n",
    "month_map = dict(\n",
    "    Jan = \"01\",\n",
    "    Feb = \"02\",\n",
    "    Mar = \"03\",\n",
    "    Apr = \"04\",\n",
    "    May = \"05\",\n",
    "    Jun = \"06\",\n",
    "    Jul = \"07\",\n",
    "    Aug = \"08\",\n",
    "    Sep = \"09\",\n",
    "    Oct = \"10\",\n",
    "    Nov = \"11\",\n",
    "    Dec = \"12\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfd1053-d01c-4d41-945a-7aef03fe7de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': {'default_name': 'ASASSN-15oi',\n",
       "  'alias': [{'value': 'ASASSN-15oi', 'reference': ['2024arXiv240719019H']}]},\n",
       " 'coordinate': [{'reference': ['2016MNRAS.463.3813H'],\n",
       "   'ra': '20:39:09.12',\n",
       "   'dec': '-30:45:20.84',\n",
       "   'ra_units': 'hourangle',\n",
       "   'dec_units': 'deg',\n",
       "   'default': True,\n",
       "   'coordinate_type': 'equitorial'}],\n",
       " 'reference_alias': [{'name': '2024arXiv240719019H',\n",
       "   'human_readable_name': 'Hajela et al. (2024)'},\n",
       "  {'name': '2016MNRAS.463.3813H',\n",
       "   'human_readable_name': 'Holoien et al. (2016)'},\n",
       "  {'name': '2020PASP..132c5001L', 'human_readable_name': 'Lucy et al. (2020)'},\n",
       "  {'name': '2017ApJ...851L..47G',\n",
       "   'human_readable_name': 'Gezari et al. (2017)'}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hajela24_bibcode = \"2024arXiv240719019H\"\n",
    "\n",
    "meta = dict(\n",
    "    name = dict(\n",
    "        default_name = \"ASASSN-15oi\",\n",
    "        alias = [dict(value=\"ASASSN-15oi\", reference=[hajela24_bibcode])]\n",
    "    ),\n",
    "\n",
    "    coordinate = [dict(\n",
    "        reference = [\"2016MNRAS.463.3813H\"],\n",
    "        ra = \"20:39:09.12\",\n",
    "        dec = \"-30:45:20.84\",\n",
    "        ra_units = \"hourangle\",\n",
    "        dec_units = \"deg\",\n",
    "        default = True,\n",
    "        coordinate_type = \"equitorial\"\n",
    "    )],\n",
    "    \n",
    "    reference_alias = [\n",
    "        dict(name=hajela24_bibcode, human_readable_name=\"Hajela et al. (2024)\"),\n",
    "        dict(name=\"2016MNRAS.463.3813H\", human_readable_name=\"Holoien et al. (2016)\"),\n",
    "        dict(name=\"2020PASP..132c5001L\", human_readable_name=\"Lucy et al. (2020)\"),\n",
    "        dict(name=\"2017ApJ...851L..47G\", human_readable_name=\"Gezari et al. (2017)\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a241b7a5-67ae-4ce0-8b8a-096148dd672f",
   "metadata": {},
   "source": [
    "### UVOIR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229b5105-74e4-4a07-b792-080187b16663",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b' 'u' 'uvm2' 'uvw1' 'uvw2' 'v']\n"
     ]
    }
   ],
   "source": [
    "uvoir = pd.read_csv(os.path.join(args.indir, \"asassn15oi_uvoir.txt\"), sep=\" \", index_col=False)\n",
    "\n",
    "uvoir_phot = dict(\n",
    "    reference = [hajela24_bibcode],\n",
    "    raw = uvoir.Magnitude.tolist(),\n",
    "    raw_err = uvoir.Magnitude_Error.tolist(),\n",
    "    raw_units = \"mag(AB)\",\n",
    "    corr_k = False,\n",
    "    corr_s = False,\n",
    "    corr_av = True,\n",
    "    corr_host = False,\n",
    "    corr_hostav = False,\n",
    "    val_av = 0.185,\n",
    "    upperlimit = [False]*len(uvoir),\n",
    "    date = uvoir.MJD.tolist(),\n",
    "    date_format = \"MJD\",\n",
    "    filter_key = uvoir[\"Filter\"].tolist(),\n",
    "    obs_type = \"uvoir\"\n",
    ")\n",
    "\n",
    "filts, idxs = np.unique(uvoir[\"Filter\"], return_index=True)\n",
    "print(filts)\n",
    "filter_alias = [\n",
    "    dict(\n",
    "        filter_key = f,\n",
    "        filter_name = f,\n",
    "        wave_eff = otter.util.FILTER_MAP_WAVE[f],\n",
    "        wave_units = \"nm\"\n",
    "    ) for f in filts\n",
    "]\n",
    "\n",
    "# test the otter dataset format based on our schema\n",
    "otter.schema.PhotometrySchema(**uvoir_phot);\n",
    "for f in filter_alias:\n",
    "    otter.schema.FilterSchema(**f);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc8e724-8184-4dd9-8485-c7e2cdee4f65",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Radio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4092ac75-de8d-4b5c-8de0-8f488762914f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfranz/.local/lib/anaconda3/lib/python3.11/site-packages/pydantic/main.py:193: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "radio = pd.read_csv(\"asassn15oi_radio.txt\", sep=\" \")\n",
    "radio_srcmap = {\n",
    "    \"this\": [hajela24_bibcode],\n",
    "    \"VLASS\": [hajela24_bibcode, \"2020PASP..132c5001L\"]\n",
    "}\n",
    "\n",
    "radio[\"iso\"] = radio.Date.replace(month_map, regex=True)\n",
    "\n",
    "radio_phot = [\n",
    "    dict(\n",
    "        reference = radio_srcmap[src],\n",
    "        raw = grp.Fν_mJy.tolist(),\n",
    "        raw_err = grp.Fv_err.tolist(),\n",
    "        raw_units = \"mJy\",\n",
    "        corr_k = False,\n",
    "        corr_s = False,\n",
    "        corr_av = False,\n",
    "        corr_host = False,\n",
    "        corr_hostav = False,\n",
    "        upperlimit = grp.upperlimit.tolist(),\n",
    "        date = grp.iso,\n",
    "        date_format = \"iso\",\n",
    "        filter_key = (grp.ν_GHz.astype(str)+[\"GHz\"]*len(grp)).tolist(),\n",
    "        obs_type = \"radio\",\n",
    "        telescope = tele\n",
    "    ) for (tele, src), grp in radio.groupby([\"Observatory\", \"Source\"])\n",
    "]\n",
    "\n",
    "filter_alias += [\n",
    "    dict(\n",
    "        filter_key = str(f)+\"GHz\",\n",
    "        filter_name = otter.util.freq_to_band(f*u.GHz),\n",
    "        freq_eff = f,\n",
    "        freq_units = \"GHz\"\n",
    "    ) for f in radio.ν_GHz.unique()\n",
    "]\n",
    "\n",
    "# test the otter dataset format based on our schema\n",
    "for r in radio_phot:\n",
    "    otter.schema.PhotometrySchema(**r);\n",
    "for f in filter_alias:\n",
    "    otter.schema.FilterSchema(**f);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c4f55b-8fc7-4391-8857-21d8c4e90f85",
   "metadata": {},
   "source": [
    "### X-ray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c53a60b2-3096-445a-bcfd-a81402971bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xray = pd.read_csv(os.path.join(args.indir, \"asassn15oi_xray.txt\"), sep=\" \")\n",
    "\n",
    "xray_srcmap = {\n",
    "    \"this\" : [hajela24_bibcode],\n",
    "    \"Gezari17\" : [hajela24_bibcode, \"2017ApJ...851L..47G\"],\n",
    "    \"Holoien18\": [hajela24_bibcode, \"2016MNRAS.463.3813H\"]\n",
    "}\n",
    "\n",
    "band_map = {\n",
    "    \"swift\" : \"0.3 - 10\",\n",
    "    \"XMM-Newton\" : \"0.2 - 12\"\n",
    "}\n",
    "\n",
    "xray[\"model_name\"] = [\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw\",\n",
    "    \"Absorbed Powerlaw\",\n",
    "    \"Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw + Blackbody\",\n",
    "    \"Absorbed Powerlaw\"\n",
    "]\n",
    "\n",
    "gPL = Param(name=\"gamma_PL\", unit=\"None\", description=\"Photon Index for Powerlaw model\")\n",
    "FPL = Param(name=\"F_PL\", unit=\"10^-14 erg/cm^2/s\", description=\"Unabsorbed flux for Powerlaw model\")\n",
    "kT = Param(name=\"kT_BB\", unit=\"10^-2 keV\", description=\"k*T for the Blackbody model\")\n",
    "FBB = Param(name=\"F_BB\", unit=\"10^-13 erg/cm^2/s\", description=\"Unabsorbed flux for Blackbody model\")\n",
    "RBB = Param(name=\"R_BB\", unit=\"10^12 cm\", description=\"Blackbody radius\")\n",
    "all_ = [gPL, FPL, kT, FBB, RBB]\n",
    "xray[\"param_names\"] = [\n",
    "    all_,\n",
    "    all_,\n",
    "    all_,\n",
    "    all_,\n",
    "    [gPL,  FPL, kT, FBB],\n",
    "    [gPL, FPL],\n",
    "    [gPL, FPL],\n",
    "    [gPL, kT, FBB, RBB],\n",
    "    all_,\n",
    "    all_,\n",
    "    [gPL, kT, FBB, RBB],\n",
    "    all_,\n",
    "    all_,\n",
    "    [gPL,  FPL, kT, FBB],\n",
    "    [gPL, FPL]\n",
    "]\n",
    "\n",
    "for p in all_:\n",
    "    xray[[p.name, p.name+\"_lower\", p.name+\"_upper\"]].astype(float)\n",
    "\n",
    "def compute_flux(row):\n",
    "    if not pd.isna(row.F_PL) and not pd.isna(row.F_BB) and not row.F_PL_upperlimit and not row.F_BB_upperlimit:\n",
    "        return (\n",
    "            row.F_PL*1e-14 + row.F_BB*1e-13, \n",
    "            (\n",
    "                np.sqrt((row.F_PL_upper*1e-14)**2 + (row.F_BB_upper*1e-13)**2) + \n",
    "                np.sqrt((row.F_PL_lower*1e-14)**2 + (row.F_BB_lower*1e-13)**2)\n",
    "            )/2,\n",
    "            False,\n",
    "            np.sqrt((row.F_PL_upper*1e-14)**2 + (row.F_BB_upper*1e-13)**2),\n",
    "            np.sqrt((row.F_PL_lower*1e-14)**2 + (row.F_BB_lower*1e-13)**2)\n",
    "        )\n",
    "            \n",
    "    elif (pd.isna(row.F_PL) or row.F_PL_upperlimit) and not pd.isna(row.F_BB) and not row.F_BB_upperlimit:\n",
    "        return row.F_BB*1e-13, (row.F_BB_upper + abs(row.F_BB_lower))/2 * 1e-13, False, row.F_BB_upper, abs(row.F_BB_lower)\n",
    "    \n",
    "    elif (pd.isna(row.F_BB) or row.F_BB_upperlimit) and not pd.isna(row.F_PL) and not row.F_PL_upperlimit:\n",
    "        return row.F_PL*1e-14, (row.F_PL_upper + abs(row.F_PL_lower))/2 * 1e-14, False, row.F_PL_upper, abs(row.F_PL_lower)\n",
    "    \n",
    "    elif row.F_PL_upperlimit:\n",
    "        return row.F_PL*1e-14, 0, True, 0, 0\n",
    "    \n",
    "    else:\n",
    "        print(row)\n",
    "        raise ValueError()\n",
    "\n",
    "xray[\"flux\"], xray[\"flux_err\"], xray[\"upperlimit\"], xray[\"flux_upper\"], xray[\"flux_lower\"] = list(zip(*xray.apply(compute_flux, axis=1).tolist()))\n",
    "        \n",
    "N_H = 5.6e20 # cm^-2\n",
    "\n",
    "xray_phot = [\n",
    "    dict(\n",
    "        reference = xray_srcmap[src],\n",
    "        raw = grp.flux.tolist(),\n",
    "        raw_err = grp.flux_err.tolist(),\n",
    "        raw_units = \"erg/s/cm^2\",\n",
    "        corr_k = False,\n",
    "        corr_s = False,\n",
    "        corr_av = False,\n",
    "        corr_host = False,\n",
    "        corr_hostav = False,\n",
    "        val_host = (grp.F_abs*1e-14).tolist(),\n",
    "        upperlimit = grp.upperlimit.tolist(),\n",
    "        date = grp.dt + 57248.0,\n",
    "        date_format = \"MJD\",\n",
    "        filter_key = band_map[tele],\n",
    "        obs_type = \"xray\",\n",
    "        telescope = tele,\n",
    "        raw_err_detail = dict(\n",
    "            upper = xray.flux_upper.tolist(),\n",
    "            lower = xray.flux_lower.tolist()\n",
    "        ),\n",
    "        xray_model = [\n",
    "            dict(\n",
    "                model_name = row.model_name,\n",
    "                param_names = [p.name for p in row.param_names],\n",
    "                param_values = [row[name.name] for name in row.param_names],\n",
    "                param_units = [p.unit for p in row.param_names],\n",
    "                param_value_err_upper = [row[name.name+\"_upper\"] for name in row.param_names],\n",
    "                param_value_err_lower = [row[name.name+\"_lower\"] for name in row.param_names],\n",
    "                param_upperlimit = [row[name.name+\"_upperlimit\"] for name in row.param_names],\n",
    "                param_descriptions = [p.description for p in row.param_names],\n",
    "                model_reference = [hajela24_bibcode],\n",
    "                min_energy = float(band_map[tele].split('-')[0].strip()),\n",
    "                max_energy = float(band_map[tele].split()[-1].strip()),\n",
    "                energy_units = \"keV\"\n",
    "            ) for _, row in grp.iterrows()\n",
    "        ]\n",
    "    ) for (src, tele), grp in xray.groupby([\"source\", \"telescope\"])\n",
    "]\n",
    "\n",
    "filter_alias += [\n",
    "    dict(\n",
    "        filter_key = \"0.3 - 10\",\n",
    "        filter_name = \"0.3 - 10\",\n",
    "        wave_eff = ((10-0.3)*u.keV).to(u.nm, equivalencies=u.spectral()).value,\n",
    "        wave_units = \"nm\",\n",
    "        wave_max = (0.3*u.keV).to(u.nm, equivalencies=u.spectral()).value,\n",
    "        wave_min = (10*u.keV).to(u.nm, equivalencies=u.spectral()).value\n",
    "    ),\n",
    "    dict(\n",
    "        filter_key = \"0.2 - 12\",\n",
    "        filter_name = \"0.2 - 12\",\n",
    "        wave_eff = ((12-0.2)*u.keV).to(u.nm, equivalencies=u.spectral()).value,\n",
    "        wave_units = \"nm\",\n",
    "        wave_max = (0.2*u.keV).to(u.nm, equivalencies=u.spectral()).value,\n",
    "        wave_min = (12*u.keV).to(u.nm, equivalencies=u.spectral()).value\n",
    "    ),\n",
    "]\n",
    "\n",
    "# test the otter dataset format based on our schema\n",
    "for r in xray_phot:\n",
    "    otter.schema.PhotometrySchema(**r);\n",
    "for f in filter_alias:\n",
    "    otter.schema.FilterSchema(**f);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c6c31-c260-4880-8b56-bd5507ed1eeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Merge everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56812712-42df-49a8-9a3c-607270da899e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfranz/.local/lib/anaconda3/lib/python3.11/site-packages/pydantic/main.py:193: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transient(\n",
       "\tName: ASASSN-15oi,\n",
       "\tKeys: dict_keys(['name', 'coordinate', 'reference_alias', 'photometry', 'filter_alias'])\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otter_json = meta | {\n",
    "    \"photometry\" : [uvoir_phot]+radio_phot+xray_phot,\n",
    "    \"filter_alias\" : filter_alias\n",
    "}\n",
    "\n",
    "otter.schema.OtterSchema(**otter_json)\n",
    "\n",
    "otter.Transient(otter_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea14af53-38aa-4809-9b39-d44862147a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASASSN-15oi\n",
      "Adding this as a new object...\n",
      "Don't need to mess with the files at all!\n",
      "Would write to .otter/ASASSN-15oi.json\n"
     ]
    }
   ],
   "source": [
    "db = otter.Otter(datadir=args.otterdir)\n",
    "\n",
    "db.save([otter.Transient(otter_json)], testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0033cd-aac9-4bef-9041-e5a1e9cf6974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
